{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a289a54",
   "metadata": {},
   "source": [
    "# ðŸ§  Machine Learning Project: Fraud Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190e8eab",
   "metadata": {},
   "source": [
    "## 1. Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0675cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic libraries for data manipulation, visualization, and timing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "# Scikit-learn tools for model training, preprocessing, evaluation\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, learning_curve\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, roc_curve, accuracy_score,\n",
    "    classification_report, confusion_matrix, precision_recall_curve\n",
    ")\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Handling imbalanced data\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Deep learning model (MLP) using Keras\n",
    "from tensorflow import keras\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc75359",
   "metadata": {},
   "source": [
    "## 2. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafd1a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the transaction dataset\n",
    "file_path = 'bank_transactions_data_2.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "print(\"Original Dataset Shape:\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41317143",
   "metadata": {},
   "source": [
    "## 3. Simulate Real-World Messiness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbba39db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inject missing values randomly into important columns to simulate real-world noise\n",
    "np.random.seed(42)\n",
    "for col in ['TransactionAmount', 'CustomerOccupation', 'Channel']:\n",
    "    df.loc[df.sample(frac=0.05).index, col] = np.nan\n",
    "\n",
    "# Duplicate a small portion of rows to simulate redundancy\n",
    "duplicates = df.sample(frac=0.01, random_state=42)\n",
    "df = pd.concat([df, duplicates], ignore_index=True)\n",
    "\n",
    "# Insert some invalid date values\n",
    "df.loc[df.sample(frac=0.01).index, 'TransactionDate'] = 'unknown_date'\n",
    "\n",
    "# Add extra whitespace to categorical text to simulate dirty data\n",
    "df['CustomerOccupation'] = df['CustomerOccupation'].astype(str).str.strip() + ' '\n",
    "df['Channel'] = ' ' + df['Channel'].astype(str).str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a112f9",
   "metadata": {},
   "source": [
    "## 4. Clean & Preprocess the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2950ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing TransactionAmount (critical field)\n",
    "df.dropna(subset=['TransactionAmount'], inplace=True)\n",
    "\n",
    "# Fill missing values in categorical columns\n",
    "df['CustomerOccupation'].fillna('Unknown', inplace=True)\n",
    "df['Channel'].fillna(df['Channel'].mode()[0], inplace=True)\n",
    "\n",
    "# Remove extra whitespaces\n",
    "df['CustomerOccupation'] = df['CustomerOccupation'].str.strip()\n",
    "df['Channel'] = df['Channel'].str.strip()\n",
    "\n",
    "# Convert dates, coerce errors to NaT, and drop those rows\n",
    "df['TransactionDate'] = pd.to_datetime(df['TransactionDate'], errors='coerce')\n",
    "df.dropna(subset=['TransactionDate'], inplace=True)\n",
    "\n",
    "# Remove duplicate rows\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "print(\"Cleaned Dataset Shape:\", df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f481c73",
   "metadata": {},
   "source": [
    "## 5. Exploratory Data Analysis (on Clean Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cebef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot target distribution: fraudulent vs. non-fraudulent\n",
    "sns.countplot(x='TransactionType', data=df)\n",
    "plt.title(\"Distribution of Transaction Types\")\n",
    "plt.show()\n",
    "\n",
    "# Correlation matrix between numeric features\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(df.select_dtypes(include='number').corr(), annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix Heatmap')\n",
    "plt.show()\n",
    "\n",
    "# Check transaction amount distribution\n",
    "sns.histplot(df['TransactionAmount'], kde=True)\n",
    "plt.title(\"Transaction Amount Distribution\")\n",
    "plt.show()\n",
    "\n",
    "# Detect outliers using a box plot\n",
    "sns.boxplot(y=df['TransactionAmount'])\n",
    "plt.title(\"Box Plot of Transaction Amount\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0c89d5",
   "metadata": {},
   "source": [
    "## 6. Feature Engineering and Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cd6c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert transaction date to a UNIX timestamp\n",
    "df['TransactionTimestamp'] = df['TransactionDate'].astype(int) / 10**9\n",
    "\n",
    "# Drop the original TransactionDate column\n",
    "df.drop(columns=['TransactionDate'], inplace=True)\n",
    "\n",
    "# Apply log transformation to reduce skew in transaction amount\n",
    "df['TransactionAmount_log'] = np.log1p(df['TransactionAmount'])\n",
    "\n",
    "# Encode categorical columns numerically\n",
    "label_enc = LabelEncoder()\n",
    "for col in ['TransactionType', 'Channel', 'CustomerOccupation', 'Location']:\n",
    "    if col in df.columns:\n",
    "        df[col] = label_enc.fit_transform(df[col].astype(str))\n",
    "\n",
    "# Drop irrelevant ID columns\n",
    "df.drop(columns=['TransactionID', 'AccountID', 'MerchantID', 'DeviceID', 'IP Address'], inplace=True, errors='ignore')\n",
    "\n",
    "# Keep only numeric columns for modeling\n",
    "df = df.select_dtypes(include='number')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
